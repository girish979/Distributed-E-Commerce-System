To set up Grafana and Prometheus together as part of a monitoring stack, you’ll need to:

1.	Deploy Prometheus to collect and store metrics.
2.	Deploy Grafana to visualize these metrics.
3.	Integrate Grafana with Prometheus to create dashboards and alerts.

Step 1: Update Docker Compose to Include Prometheus and Grafana

Here’s how to add Prometheus and Grafana services to your existing Docker Compose file:

Updated Docker Compose

```yaml
  redis-exporter:
    image: oliver006/redis_exporter
    ports:
      - "9121:9121"
    environment:
      REDIS_ADDR: "redis-node1:6379,redis-node2:6380,redis-node3:6381,redis-node4:6382,redis-node5:6383,redis-node6:6384"
    networks:
      - cockroachnet

  # Prometheus service
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus:/etc/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - '9090:9090'
    networks:
      - cockroachnet

  # Grafana service
  grafana:
    image: grafana/grafana-oss:latest
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - '3000:3000'
    networks:
      - cockroachnet
    depends_on:
      - prometheus
```
Step 2: Configure Prometheus to Scrape Metrics

You need a Prometheus configuration file to define which targets to scrape metrics from.

Create the Prometheus Configuration File

Create a file named prometheus.yml inside a folder called prometheus in your project directory.

`prometheus/prometheus.yml`
```
global:
  scrape_interval: 15s  # Scrape every 15 seconds

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka1:9991', 'kafka2:9992', 'kafka3:9993']

  # Scrape Redis metrics using Redis Exporter
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'cockroachdb'
    static_configs:
      - targets: ['cockroachdb1:8080', 'cockroachdb2:8081', 'cockroachdb3:8082']

  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100']
```
Explanation

	•	scrape_interval: 15s: Prometheus will scrape metrics from the defined targets every 15 seconds.
	•	job_name: Specifies the target job name (e.g., Kafka, Redis, CockroachDB).
	•	static_configs: Lists the targets for Prometheus to scrape metrics from.

Step 3: Start the Docker Containers


Step 4: Access Grafana and Add Prometheus as a Data Source

	1.	Open Grafana in your browser:
	•	Navigate to http://localhost:3000.
	•	Log in with the default credentials:
	•	Username: admin
	•	Password: admin
	2.	Add Prometheus as a Data Source:
	•	Go to Configuration (gear icon) > Data Sources > Add Data Source.
	•	Select Prometheus as the data source.
	•	Set the URL to http://prometheus:9090 (matching the Docker service name and port).
	•	Click Save & Test to confirm the connection.

Step 5: Create Dashboards in Grafana

Option 1:
Import Pre-built Dashboards

Grafana has many pre-built dashboards for Kafka, Redis, and CockroachDB:

1.	Go to Dashboards > Import.
2.	Use the following Dashboard IDs for quick import:
	•	Kafka Dashboard ID: 7589 (Kafka Exporter Overview)  
	•	Redis Dashboard ID: 763 (Redis Overview)  
	•	CockroachDB Dashboard ID: 11326 (CockroachDB Overview)  
3.	Enter the dashboard ID and click Load.
4.	Select the Prometheus data source and click Import.

Option 2:

1.	Go to the Dashboards section in Grafana and click + New Dashboard.
2.	Click Add Query, select the Prometheus data source, and use PromQL to query metrics.

Example PromQL Queries

•	Kafka Metrics:

```
sum(rate(kafka_server_brokertopicmetrics_messagesin_total[5m])) by (broker)
```

•	This query shows the rate of messages produced per broker.

•	Redis Metrics:

```
redis_memory_used_bytes{job="redis"}
```

•	This shows the memory used by Redis nodes.

•	CockroachDB Metrics:

```
rate(cockroach_queries_per_second[5m])
```

•	This shows the rate of queries processed by CockroachDB over 5 minutes.

#### Enable JMX Exporter for Kafka Metrics

* 	**JMX Exporter** is a tool that exposes Kafka metrics in a format that Prometheus can scrape.
* 	Update your Docker Compose to include JMX Exporter with each Kafka broker:

**Docker Compose Update for Kafka**
```yaml
  kafka1:
    image: bitnami/kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9991
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=9991 -Dcom.sun.management.jmxremote.rmi.port=19991 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9991:9991"
      - "19991:19991"
    networks:
      - cockroachnet
    depends_on:
      - zookeeper

  kafka2:
    image: bitnami/kafka:latest
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093,PLAINTEXT_HOST://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9992
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=9992 -Dcom.sun.management.jmxremote.rmi.port=19992 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    ports:
      - "9093:9093"
      - "29093:29093"
      - "9992:9992"
      - "19992:19992"
    networks:
      - cockroachnet
    depends_on:
      - zookeeper

  kafka3:
    image: bitnami/kafka:latest
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9094,PLAINTEXT_HOST://0.0.0.0:29094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094,PLAINTEXT_HOST://localhost:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9993
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=9993 -Dcom.sun.management.jmxremote.rmi.port=19993 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    ports:
      - "9094:9094"
      - "29094:29094"
      - "9993:9993"
      - "19993:19993"
    networks:
      - cockroachnet
    depends_on:
      - zookeeper
  
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9093,kafka3:9094
    networks:
      - cockroachnet
    depends_on:
      - kafka1
      - kafka2
      - kafka3

```
	* 	The JMX exporter exposes metrics such as:
	* 	**Message rate per broker**
	* 	**Producer/consumer latency**
	* 	**Topic partition assignments**
	* 	**Replication lag**

Also added the kafka-ui to view directly without grafana

